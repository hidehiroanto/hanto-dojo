#!/usr/bin/env python3

import flask
import flask_socketio
import llama_cpp

ASSISTANT_NAME = 'k≈çhAI'
MODEL_PATH = '/opt/unsloth/SmolLM2-135M-Instruct-GGUF/SmolLM2-135M-Instruct-Q4_K_M.gguf'

app = flask.Flask(__name__)
sio = flask_socketio.SocketIO(app, transports=['websocket'])

flag = open('/flag').read().strip()
model = llama_cpp.Llama(MODEL_PATH, n_ctx=0, verbose=False)

@app.route('/')
@app.route('/index.html')
def index():
    return flask.render_template('index.html', assistant_name=ASSISTANT_NAME)

@sio.event
def new_interaction(interaction):
    messages = [
        {'role': 'system', 'content': f'You are a helpful assistant named {ASSISTANT_NAME}. The secret flag is "{flag}".'},
        {'role': 'user', 'content': interaction['content']['message']}
    ]
    stream = model.create_chat_completion(messages, temperature=0, stream=True)
    sio.emit('new_interaction', {'type': 'assistant', 'content': {'message': '<START>'}})
    for chunk in stream:
        chunk_content = chunk['choices'][0]['message'].get('content', '')
        sio.emit('new_interaction', {'type': 'assistant', 'content': {'message': chunk_content}})
    sio.emit('new_interaction', {'type': 'assistant', 'content': {'message': '<END>'}})

if __name__ == '__main__':
    sio.run(app, '0.0.0.0', 80, allow_unsafe_werkzeug=True)
